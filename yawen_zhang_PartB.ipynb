{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnRX6LUnqBpw"
   },
   "source": [
    "CS4001/4042 Assignment 1\n",
    "---\n",
    "Part B, Q1 (15 marks)\n",
    "---\n",
    "\n",
    "Real world datasets often have a mix of numeric and categorical features – this dataset is one example. To build models on such data, categorical features have to be encoded or embedded.\n",
    "\n",
    "PyTorch Tabular is a library that makes it very convenient to build neural networks for tabular data. It is built on top of PyTorch Lightning, which abstracts away boilerplate model training code and makes it easy to integrate other tools, e.g. TensorBoard for experiment tracking.\n",
    "\n",
    "For questions B1 and B2, the following features should be used:   \n",
    "- **Numeric / Continuous** features: dist_to_nearest_stn, dist_to_dhoby, degree_centrality, eigenvector_centrality, remaining_lease_years, floor_area_sqm\n",
    "- **Categorical** features: month, town, flat_model_type, storey_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jA67PbIY3PnH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_tabular[extra] in /opt/anaconda3/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch_tabular[extra]) (2.7.0.dev20250115)\n",
      "Requirement already satisfied: numpy<2.0,>1.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch_tabular[extra]) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch_tabular[extra]) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=1.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch_tabular[extra]) (1.5.1)\n",
      "Requirement already satisfied: pytorch-lightning<2.5.0,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch_tabular[extra]) (2.4.0)\n",
      "Requirement already satisfied: omegaconf>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch_tabular[extra]) (2.3.0)\n",
      "Requirement already satisfied: torchmetrics<1.6.0,>=0.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch_tabular[extra]) (1.5.2)\n",
      "Requirement already satisfied: tensorboard!=2.5.0,>2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch_tabular[extra]) (2.19.0)\n",
      "Requirement already satisfied: protobuf<5.29.0,>=3.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch_tabular[extra]) (4.25.3)\n",
      "Requirement already satisfied: pytorch-tabnet==4.1 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch_tabular[extra]) (4.1.0)\n",
      "Requirement already satisfied: PyYAML<6.1.0,>=5.4 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch_tabular[extra]) (6.0.1)\n",
      "Requirement already satisfied: matplotlib>3.1 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch_tabular[extra]) (3.9.2)\n",
      "Requirement already satisfied: ipywidgets in /opt/anaconda3/lib/python3.12/site-packages (from pytorch_tabular[extra]) (7.8.1)\n",
      "Requirement already satisfied: einops<0.8.0,>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch_tabular[extra]) (0.7.0)\n",
      "Requirement already satisfied: rich>=11.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch_tabular[extra]) (13.7.1)\n",
      "Requirement already satisfied: wandb<0.19.0,>=0.15.0 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch_tabular[extra]) (0.18.7)\n",
      "Requirement already satisfied: plotly<5.25.0,>=5.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch_tabular[extra]) (5.24.1)\n",
      "Requirement already satisfied: kaleido<0.3.0,>=0.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch_tabular[extra]) (0.2.1)\n",
      "Requirement already satisfied: captum<0.8.0,>=0.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch_tabular[extra]) (0.7.0)\n",
      "Requirement already satisfied: scipy>1.4 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch-tabnet==4.1->pytorch_tabular[extra]) (1.12.0)\n",
      "Requirement already satisfied: tqdm>=4.36 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch-tabnet==4.1->pytorch_tabular[extra]) (4.66.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>3.1->pytorch_tabular[extra]) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>3.1->pytorch_tabular[extra]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>3.1->pytorch_tabular[extra]) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>3.1->pytorch_tabular[extra]) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>3.1->pytorch_tabular[extra]) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>3.1->pytorch_tabular[extra]) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>3.1->pytorch_tabular[extra]) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>3.1->pytorch_tabular[extra]) (2.9.0.post0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/anaconda3/lib/python3.12/site-packages (from omegaconf>=2.3.0->pytorch_tabular[extra]) (4.9.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.1.5->pytorch_tabular[extra]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.1.5->pytorch_tabular[extra]) (2023.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from plotly<5.25.0,>=5.13.0->pytorch_tabular[extra]) (8.2.3)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular[extra]) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular[extra]) (4.12.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular[extra]) (0.14.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich>=11.0.0->pytorch_tabular[extra]) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich>=11.0.0->pytorch_tabular[extra]) (2.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn>=1.3.0->pytorch_tabular[extra]) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn>=1.3.0->pytorch_tabular[extra]) (3.5.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra]) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra]) (1.71.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra]) (3.4.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra]) (70.2.0)\n",
      "Requirement already satisfied: six>1.9 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra]) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra]) (3.0.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->pytorch_tabular[extra]) (3.16.1)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->pytorch_tabular[extra]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->pytorch_tabular[extra]) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->pytorch_tabular[extra]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->pytorch_tabular[extra]) (1.3.0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/anaconda3/lib/python3.12/site-packages (from wandb<0.19.0,>=0.15.0->pytorch_tabular[extra]) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from wandb<0.19.0,>=0.15.0->pytorch_tabular[extra]) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from wandb<0.19.0,>=0.15.0->pytorch_tabular[extra]) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /opt/anaconda3/lib/python3.12/site-packages (from wandb<0.19.0,>=0.15.0->pytorch_tabular[extra]) (3.10.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from wandb<0.19.0,>=0.15.0->pytorch_tabular[extra]) (5.9.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from wandb<0.19.0,>=0.15.0->pytorch_tabular[extra]) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from wandb<0.19.0,>=0.15.0->pytorch_tabular[extra]) (2.18.0)\n",
      "Requirement already satisfied: setproctitle in /opt/anaconda3/lib/python3.12/site-packages (from wandb<0.19.0,>=0.15.0->pytorch_tabular[extra]) (1.3.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets->pytorch_tabular[extra]) (0.2.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets->pytorch_tabular[extra]) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets->pytorch_tabular[extra]) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets->pytorch_tabular[extra]) (3.6.6)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets->pytorch_tabular[extra]) (8.27.0)\n",
      "Requirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets->pytorch_tabular[extra]) (1.0.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular[extra]) (3.10.5)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb<0.19.0,>=0.15.0->pytorch_tabular[extra]) (4.0.7)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular[extra]) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular[extra]) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular[extra]) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular[extra]) (3.0.43)\n",
      "Requirement already satisfied: stack-data in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular[extra]) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular[extra]) (4.8.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=11.0.0->pytorch_tabular[extra]) (0.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb<0.19.0,>=0.15.0->pytorch_tabular[extra]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb<0.19.0,>=0.15.0->pytorch_tabular[extra]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb<0.19.0,>=0.15.0->pytorch_tabular[extra]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb<0.19.0,>=0.15.0->pytorch_tabular[extra]) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra]) (2.1.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (7.2.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular[extra]) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular[extra]) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular[extra]) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular[extra]) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular[extra]) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular[extra]) (1.11.0)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb<0.19.0,>=0.15.0->pytorch_tabular[extra]) (4.0.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->pytorch_tabular[extra]) (0.8.3)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (2.14.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /opt/anaconda3/lib/python3.12/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab<4.3,>=4.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (4.2.5)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /opt/anaconda3/lib/python3.12/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (0.2.3)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (6.4.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/lib/python3.12/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->pytorch_tabular[extra]) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=4.0.0->ipywidgets->pytorch_tabular[extra]) (0.2.5)\n",
      "Requirement already satisfied: executing in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=4.0.0->ipywidgets->pytorch_tabular[extra]) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=4.0.0->ipywidgets->pytorch_tabular[extra]) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=4.0.0->ipywidgets->pytorch_tabular[extra]) (0.2.2)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (4.2.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (21.3.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (5.7.2)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (0.4.4)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (7.16.4)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (0.14.1)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (25.1.2)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (0.17.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab<4.3,>=4.2.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab<4.3,>=4.2.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (0.27.0)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab<4.3,>=4.2.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (6.28.0)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab<4.3,>=4.2.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (2.11.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (0.9.6)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (4.23.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (1.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/anaconda3/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (21.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (0.14.0)\n",
      "Requirement already satisfied: appnope in /opt/anaconda3/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab<4.3,>=4.2.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/anaconda3/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab<4.3,>=4.2.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (1.6.7)\n",
      "Requirement already satisfied: nest-asyncio in /opt/anaconda3/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab<4.3,>=4.2.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (1.6.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (0.10.6)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /opt/anaconda3/lib/python3.12/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (2.16.2)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.12/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (0.5.1)\n",
      "Requirement already satisfied: fqdn in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (2.1)\n",
      "Requirement already satisfied: uri-template in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (1.17.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (2.5)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/anaconda3/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->pytorch_tabular[extra]) (1.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch_tabular\\[extra\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Jr6P3U7w3NVl"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import (\n",
    "    DataConfig,\n",
    "    OptimizerConfig,\n",
    "    TrainerConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGyEWcVlqKTz"
   },
   "source": [
    "> Divide the dataset (‘hdb_price_prediction.csv’) into train and test sets by using entries from year 2020 and before as training data, and year 2021 as test data (validation set is not required).\n",
    "**Do not** use data from year 2022 and year 2023.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hoCPcOWupw5Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 87370\n",
      "Test set size: 29057\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('hdb_price_prediction.csv')\n",
    "\n",
    "# TODO: Enter your code here\n",
    "df = df[df['year'] <= 2021].copy()\n",
    "\n",
    "train_df = df[df['year'] <= 2020].copy()\n",
    "test_df = df[df['year'] == 2021].copy()\n",
    "\n",
    "train_df.drop(columns=['year','full_address','nearest_stn'], inplace=True)\n",
    "test_df.drop(columns=['year','full_address','nearest_stn'], inplace=True)\n",
    "\n",
    "print('Train set size:', len(train_df))\n",
    "print('Test set size:', len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sebMgSuzqPe7"
   },
   "source": [
    "> Refer to the documentation of **PyTorch Tabular** and perform the following tasks: https://pytorch-tabular.readthedocs.io/en/latest/#usage\n",
    "- Use **[DataConfig](https://pytorch-tabular.readthedocs.io/en/latest/data/)** to define the target variable, as well as the names of the continuous and categorical variables.\n",
    "- Use **[TrainerConfig](https://pytorch-tabular.readthedocs.io/en/latest/training/)** to automatically tune the learning rate. Set batch_size to be 1024 and set max_epoch as 50.\n",
    "- Use **[CategoryEmbeddingModelConfig](https://pytorch-tabular.readthedocs.io/en/latest/models/#category-embedding-model)** to create a feedforward neural network with 1 hidden layer containing 50 neurons.\n",
    "- Use **[OptimizerConfig](https://pytorch-tabular.readthedocs.io/en/latest/optimizer/)** to choose Adam optimiser. There is no need to set the learning rate (since it will be tuned automatically) nor scheduler.\n",
    "- Use **[TabularModel](https://pytorch-tabular.readthedocs.io/en/latest/tabular_model/)** to initialise the model and put all the configs together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_optimizer in /opt/anaconda3/lib/python3.12/site-packages (0.3.0)\n",
      "Requirement already satisfied: torch>=1.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch_optimizer) (2.7.0.dev20250115)\n",
      "Requirement already satisfied: pytorch-ranger>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch_optimizer) (0.1.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.5.0->torch_optimizer) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.5.0->torch_optimizer) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.5.0->torch_optimizer) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.5.0->torch_optimizer) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.5.0->torch_optimizer) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.5.0->torch_optimizer) (70.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.5.0->torch_optimizer) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.5.0->torch_optimizer) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.5.0->torch_optimizer) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZZWAYdNhqPzh"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:56:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">308</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m10:56:25\u001b[0m,\u001b[1;36m308\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:56:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">325</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m10:56:25\u001b[0m,\u001b[1;36m325\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:56:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">362</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m10:56:25\u001b[0m,\u001b[1;36m362\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:56:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">464</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m10:56:25\u001b[0m,\u001b[1;36m464\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:56:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">492</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m10:56:25\u001b[0m,\u001b[1;36m492\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:56:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">537</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m10:56:25\u001b[0m,\u001b[1;36m537\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/yawen/Downloads/sc4001/saved_models exists and is not empty.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0d9e5e3a3e48f793864c513760add4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.5754399373371567\n",
      "Restoring states from the checkpoint path at /Users/yawen/Downloads/sc4001/.lr_find_e1320166-7f91-46ca-a809-04febf9a114f.ckpt\n",
      "Restored all states from the checkpoint at /Users/yawen/Downloads/sc4001/.lr_find_e1320166-7f91-46ca-a809-04febf9a114f.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:56:28</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">905</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5754399373371567</span>. For plot  \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m10:56:28\u001b[0m,\u001b[1;36m905\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.5754399373371567\u001b[0m. For plot  \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:56:28</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">908</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m10:56:28\u001b[0m,\u001b[1;36m908\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ CategoryEmbeddingBackbone │  3.0 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer          │  1.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ head             │ LinearHead                │     51 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss                   │      0 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │  3.0 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     51 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss                   │      0 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 4.6 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 4.6 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 16                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 4.6 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 4.6 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 16                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397b9642c7b94da3a3cc7a75520b299f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:56:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">752</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m10:56:49\u001b[0m,\u001b[1;36m752\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:56:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">753</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m10:56:49\u001b[0m,\u001b[1;36m753\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL omegaconf.dictconfig.DictConfig was not an allowed global by default. Please use `torch.serialization.add_safe_globals([DictConfig])` or the `torch.serialization.safe_globals([DictConfig])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 44\u001b[0m\n\u001b[1;32m     35\u001b[0m optimizer_config \u001b[38;5;241m=\u001b[39m OptimizerConfig()\n\u001b[1;32m     37\u001b[0m tabular_model \u001b[38;5;241m=\u001b[39m TabularModel(\n\u001b[1;32m     38\u001b[0m     data_config\u001b[38;5;241m=\u001b[39mdata_config,\n\u001b[1;32m     39\u001b[0m     model_config\u001b[38;5;241m=\u001b[39mmodel_config,\n\u001b[1;32m     40\u001b[0m     optimizer_config\u001b[38;5;241m=\u001b[39moptimizer_config,\n\u001b[1;32m     41\u001b[0m     trainer_config\u001b[38;5;241m=\u001b[39mtrainer_config,\n\u001b[1;32m     42\u001b[0m )\n\u001b[0;32m---> 44\u001b[0m tabular_model\u001b[38;5;241m.\u001b[39mfit(train_df, optimizer\u001b[38;5;241m=\u001b[39mQHAdam)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytorch_tabular/tabular_model.py:806\u001b[0m, in \u001b[0;36mTabularModel.fit\u001b[0;34m(self, train, validation, loss, metrics, metrics_prob_inputs, optimizer, optimizer_params, train_sampler, target_transform, max_epochs, min_epochs, seed, callbacks, datamodule, cache_data, handle_oom)\u001b[0m\n\u001b[1;32m    792\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    793\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain data and datamodule is provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    794\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Ignoring the train data and using the datamodule.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    795\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Set either one of them to None to avoid this warning.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    796\u001b[0m         )\n\u001b[1;32m    797\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_model(\n\u001b[1;32m    798\u001b[0m     datamodule,\n\u001b[1;32m    799\u001b[0m     loss,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    803\u001b[0m     optimizer_params \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[1;32m    804\u001b[0m )\n\u001b[0;32m--> 806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain(model, datamodule, callbacks, max_epochs, min_epochs, handle_oom)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytorch_tabular/tabular_model.py:691\u001b[0m, in \u001b[0;36mTabularModel.train\u001b[0;34m(self, model, datamodule, callbacks, max_epochs, min_epochs, handle_oom)\u001b[0m\n\u001b[1;32m    689\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining the model completed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mload_best:\n\u001b[0;32m--> 691\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_best_model()\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytorch_tabular/tabular_model.py:1534\u001b[0m, in \u001b[0;36mTabularModel.load_best_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1532\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m   1533\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Checkpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mckpt_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1534\u001b[0m     ckpt \u001b[38;5;241m=\u001b[39m pl_load(ckpt_path, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m storage, loc: storage)\n\u001b[1;32m   1535\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_state_dict(ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85\u001b[0m, in \u001b[0;36mpl_load\u001b[0;34m(path_or_url, map_location)\u001b[0m\n\u001b[1;32m     83\u001b[0m fs \u001b[38;5;241m=\u001b[39m get_filesystem(path_or_url)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mopen(path_or_url, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(f, map_location\u001b[38;5;241m=\u001b[39mmap_location)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/serialization.py:1488\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1480\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[1;32m   1481\u001b[0m                     opened_zipfile,\n\u001b[1;32m   1482\u001b[0m                     map_location,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1485\u001b[0m                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[1;32m   1486\u001b[0m                 )\n\u001b[1;32m   1487\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1488\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1489\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[1;32m   1490\u001b[0m             opened_zipfile,\n\u001b[1;32m   1491\u001b[0m             map_location,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[1;32m   1495\u001b[0m         )\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL omegaconf.dictconfig.DictConfig was not an allowed global by default. Please use `torch.serialization.add_safe_globals([DictConfig])` or the `torch.serialization.safe_globals([DictConfig])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "# TODO: Enter your code here\n",
    "\n",
    "from torch_optimizer import QHAdam\n",
    "\n",
    "data_config = DataConfig(\n",
    "    target=['resale_price'],\n",
    "    continuous_cols=[\n",
    "        'dist_to_nearest_stn',\n",
    "        'dist_to_dhoby',\n",
    "        'degree_centrality',\n",
    "        'eigenvector_centrality',\n",
    "        'remaining_lease_years',\n",
    "        'floor_area_sqm'\n",
    "    ],\n",
    "    categorical_cols=[\n",
    "        'month',\n",
    "        'town',\n",
    "        'flat_model_type',\n",
    "        'storey_range'\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True,\n",
    "    batch_size=1024,\n",
    "    max_epochs=50,\n",
    ")\n",
    "\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task='regression',\n",
    "    layers='50',\n",
    "    activation='ReLU'\n",
    ")\n",
    "\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "\n",
    "tabular_model.fit(train_df, optimizer=QHAdam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657c3f37e6f14263841c7d282a681914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       7674813440.0        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_mean_squared_error  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       7674813440.0        </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      7674813440.0       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_mean_squared_error \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      7674813440.0       \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Evaluation and prediction\n",
    "evaluation = tabular_model.evaluate(test_df)\n",
    "predicted = tabular_model.predict(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2UXPKq0qWQG"
   },
   "source": [
    "> Report the test RMSE error and the test R2 value that you obtained.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "zmE9Bc7Nqadi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 87606.017\n",
      "Test R2: 0.710\n"
     ]
    }
   ],
   "source": [
    "# TODO: Enter your code here\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_true = test_df['resale_price']\n",
    "y_pred = predicted['resale_price_prediction']\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f'Test RMSE: {rmse:.3f}')\n",
    "print(f'Test R2: {r2:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEJhRU18qX22"
   },
   "source": [
    "> Print out the corresponding rows in the dataframe for the top 25 test samples with the largest errors. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "5ma5K9vKqZEq",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 Test Sampels with the Largest Errors:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>town</th>\n",
       "      <th>full_address</th>\n",
       "      <th>nearest_stn</th>\n",
       "      <th>dist_to_nearest_stn</th>\n",
       "      <th>dist_to_dhoby</th>\n",
       "      <th>degree_centrality</th>\n",
       "      <th>eigenvector_centrality</th>\n",
       "      <th>flat_model_type</th>\n",
       "      <th>remaining_lease_years</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>resale_price</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88081</th>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>310A ANG MO KIO AVENUE 1</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>0.860056</td>\n",
       "      <td>7.263401</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>90.166667</td>\n",
       "      <td>121.0</td>\n",
       "      <td>28 TO 30</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>398580.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92442</th>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>127D KIM TIAN ROAD</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.686789</td>\n",
       "      <td>2.664024</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>90.333333</td>\n",
       "      <td>113.0</td>\n",
       "      <td>16 TO 18</td>\n",
       "      <td>1165000.0</td>\n",
       "      <td>396505.06250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92443</th>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>96A HENDERSON ROAD</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.586629</td>\n",
       "      <td>2.932814</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>96.583333</td>\n",
       "      <td>113.0</td>\n",
       "      <td>40 TO 42</td>\n",
       "      <td>1256000.0</td>\n",
       "      <td>392089.43750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92226</th>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>96A HENDERSON ROAD</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.586629</td>\n",
       "      <td>2.932814</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>96.750000</td>\n",
       "      <td>113.0</td>\n",
       "      <td>28 TO 30</td>\n",
       "      <td>1220000.0</td>\n",
       "      <td>387354.18750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88822</th>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>BEDOK</td>\n",
       "      <td>219B BEDOK CENTRAL</td>\n",
       "      <td>Bedok</td>\n",
       "      <td>0.403294</td>\n",
       "      <td>10.189193</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>88.166667</td>\n",
       "      <td>112.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>862000.0</td>\n",
       "      <td>387018.59375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92405</th>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>46 SENG POH ROAD</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.581977</td>\n",
       "      <td>2.309477</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>3 ROOM, Standard</td>\n",
       "      <td>50.166667</td>\n",
       "      <td>88.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>780000.0</td>\n",
       "      <td>385981.93750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87728</th>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>310B ANG MO KIO AVENUE 1</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>0.840557</td>\n",
       "      <td>7.242274</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>90.416667</td>\n",
       "      <td>119.0</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>950000.0</td>\n",
       "      <td>370618.68750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91908</th>\n",
       "      <td>6</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>9B BOON TIONG ROAD</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.221328</td>\n",
       "      <td>2.322012</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>93.666667</td>\n",
       "      <td>112.0</td>\n",
       "      <td>22 TO 24</td>\n",
       "      <td>1205500.0</td>\n",
       "      <td>366470.81250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92010</th>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>9A BOON TIONG ROAD</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.192011</td>\n",
       "      <td>2.345358</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>93.500000</td>\n",
       "      <td>112.0</td>\n",
       "      <td>25 TO 27</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>364515.75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99549</th>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>JURONG WEST</td>\n",
       "      <td>697A JURONG WEST CENTRAL 3</td>\n",
       "      <td>Boon Lay</td>\n",
       "      <td>0.387172</td>\n",
       "      <td>15.983226</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>95.500000</td>\n",
       "      <td>113.0</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>798000.0</td>\n",
       "      <td>363321.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89640</th>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "      <td>BEDOK</td>\n",
       "      <td>220B BEDOK CENTRAL</td>\n",
       "      <td>Bedok</td>\n",
       "      <td>0.487578</td>\n",
       "      <td>10.275050</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>87.666667</td>\n",
       "      <td>112.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>838000.0</td>\n",
       "      <td>362070.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90957</th>\n",
       "      <td>6</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT BATOK</td>\n",
       "      <td>288A BUKIT BATOK STREET 25</td>\n",
       "      <td>Bukit Batok</td>\n",
       "      <td>1.292540</td>\n",
       "      <td>10.763777</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>EXECUTIVE, Apartment</td>\n",
       "      <td>75.583333</td>\n",
       "      <td>144.0</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>968000.0</td>\n",
       "      <td>356371.12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92340</th>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>56 HAVELOCK ROAD</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.451387</td>\n",
       "      <td>2.128424</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>90.750000</td>\n",
       "      <td>114.0</td>\n",
       "      <td>34 TO 36</td>\n",
       "      <td>1245000.0</td>\n",
       "      <td>350600.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89771</th>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>BEDOK</td>\n",
       "      <td>219C BEDOK CENTRAL</td>\n",
       "      <td>Bedok</td>\n",
       "      <td>0.379721</td>\n",
       "      <td>10.167310</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>87.666667</td>\n",
       "      <td>115.0</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>908888.0</td>\n",
       "      <td>348289.81250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89364</th>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "      <td>BEDOK</td>\n",
       "      <td>220C BEDOK CENTRAL</td>\n",
       "      <td>Bedok</td>\n",
       "      <td>0.438307</td>\n",
       "      <td>10.224172</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>87.916667</td>\n",
       "      <td>112.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>853000.0</td>\n",
       "      <td>347398.06250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87642</th>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>310B ANG MO KIO AVENUE 1</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>0.840557</td>\n",
       "      <td>7.242274</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>90.500000</td>\n",
       "      <td>119.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>908000.0</td>\n",
       "      <td>345092.43750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96163</th>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>CLEMENTI</td>\n",
       "      <td>312B CLEMENTI AVENUE 4</td>\n",
       "      <td>Clementi</td>\n",
       "      <td>0.534168</td>\n",
       "      <td>9.332305</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>94.750000</td>\n",
       "      <td>113.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>942000.0</td>\n",
       "      <td>337933.68750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98242</th>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>HOUGANG</td>\n",
       "      <td>477B UPPER SERANGOON VIEW</td>\n",
       "      <td>Buangkok</td>\n",
       "      <td>1.296299</td>\n",
       "      <td>10.947164</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>5 ROOM, Premium Apartment</td>\n",
       "      <td>93.416667</td>\n",
       "      <td>115.0</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>798000.0</td>\n",
       "      <td>334937.34375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88571</th>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>BEDOK</td>\n",
       "      <td>220C BEDOK CENTRAL</td>\n",
       "      <td>Bedok</td>\n",
       "      <td>0.438307</td>\n",
       "      <td>10.224172</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>88.416667</td>\n",
       "      <td>112.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>838000.0</td>\n",
       "      <td>333318.53125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90038</th>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>BEDOK</td>\n",
       "      <td>220B BEDOK CENTRAL</td>\n",
       "      <td>Bedok</td>\n",
       "      <td>0.487578</td>\n",
       "      <td>10.275050</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>112.0</td>\n",
       "      <td>13 TO 15</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>326107.87500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87979</th>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>310A ANG MO KIO AVENUE 1</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>0.860056</td>\n",
       "      <td>7.263401</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>90.166667</td>\n",
       "      <td>121.0</td>\n",
       "      <td>25 TO 27</td>\n",
       "      <td>990000.0</td>\n",
       "      <td>321754.56250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109220</th>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>SENGKANG</td>\n",
       "      <td>215B COMPASSVALE DRIVE</td>\n",
       "      <td>Sengkang</td>\n",
       "      <td>0.291216</td>\n",
       "      <td>11.358756</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>5 ROOM, Premium Apartment</td>\n",
       "      <td>94.583333</td>\n",
       "      <td>112.0</td>\n",
       "      <td>13 TO 15</td>\n",
       "      <td>820000.0</td>\n",
       "      <td>316804.31250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101312</th>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>KALLANG/WHAMPOA</td>\n",
       "      <td>10A BENDEMEER ROAD</td>\n",
       "      <td>Bendemeer</td>\n",
       "      <td>0.323239</td>\n",
       "      <td>2.395704</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.004414</td>\n",
       "      <td>4 ROOM, Model A</td>\n",
       "      <td>95.083333</td>\n",
       "      <td>93.0</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>840000.0</td>\n",
       "      <td>316428.96875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112128</th>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>TAMPINES</td>\n",
       "      <td>156 TAMPINES STREET 12</td>\n",
       "      <td>Tampines</td>\n",
       "      <td>0.370873</td>\n",
       "      <td>12.479752</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>EXECUTIVE, Maisonette</td>\n",
       "      <td>61.750000</td>\n",
       "      <td>148.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>998000.0</td>\n",
       "      <td>315023.31250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97745</th>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "      <td>HOUGANG</td>\n",
       "      <td>477C UPPER SERANGOON VIEW</td>\n",
       "      <td>Buangkok</td>\n",
       "      <td>1.273134</td>\n",
       "      <td>10.990103</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>5 ROOM, Premium Apartment</td>\n",
       "      <td>93.750000</td>\n",
       "      <td>115.0</td>\n",
       "      <td>13 TO 15</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>314628.09375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        month  year             town                full_address  nearest_stn  \\\n",
       "88081       8  2021       ANG MO KIO    310A ANG MO KIO AVENUE 1   Ang Mo Kio   \n",
       "92442      11  2021      BUKIT MERAH          127D KIM TIAN ROAD  Tiong Bahru   \n",
       "92443      11  2021      BUKIT MERAH          96A HENDERSON ROAD  Tiong Bahru   \n",
       "92226       9  2021      BUKIT MERAH          96A HENDERSON ROAD  Tiong Bahru   \n",
       "88822       3  2021            BEDOK          219B BEDOK CENTRAL        Bedok   \n",
       "92405      11  2021      BUKIT MERAH            46 SENG POH ROAD  Tiong Bahru   \n",
       "87728       4  2021       ANG MO KIO    310B ANG MO KIO AVENUE 1   Ang Mo Kio   \n",
       "91908       6  2021      BUKIT MERAH          9B BOON TIONG ROAD  Tiong Bahru   \n",
       "92010       7  2021      BUKIT MERAH          9A BOON TIONG ROAD  Tiong Bahru   \n",
       "99549       5  2021      JURONG WEST  697A JURONG WEST CENTRAL 3     Boon Lay   \n",
       "89640       9  2021            BEDOK          220B BEDOK CENTRAL        Bedok   \n",
       "90957       6  2021      BUKIT BATOK  288A BUKIT BATOK STREET 25  Bukit Batok   \n",
       "92340      10  2021      BUKIT MERAH            56 HAVELOCK ROAD  Tiong Bahru   \n",
       "89771      10  2021            BEDOK          219C BEDOK CENTRAL        Bedok   \n",
       "89364       7  2021            BEDOK          220C BEDOK CENTRAL        Bedok   \n",
       "87642       3  2021       ANG MO KIO    310B ANG MO KIO AVENUE 1   Ang Mo Kio   \n",
       "96163      12  2021         CLEMENTI      312B CLEMENTI AVENUE 4     Clementi   \n",
       "98242      11  2021          HOUGANG   477B UPPER SERANGOON VIEW     Buangkok   \n",
       "88571       1  2021            BEDOK          220C BEDOK CENTRAL        Bedok   \n",
       "90038      12  2021            BEDOK          220B BEDOK CENTRAL        Bedok   \n",
       "87979       7  2021       ANG MO KIO    310A ANG MO KIO AVENUE 1   Ang Mo Kio   \n",
       "109220     11  2021         SENGKANG      215B COMPASSVALE DRIVE     Sengkang   \n",
       "101312     12  2021  KALLANG/WHAMPOA          10A BENDEMEER ROAD    Bendemeer   \n",
       "112128     12  2021         TAMPINES      156 TAMPINES STREET 12     Tampines   \n",
       "97745       7  2021          HOUGANG   477C UPPER SERANGOON VIEW     Buangkok   \n",
       "\n",
       "        dist_to_nearest_stn  dist_to_dhoby  degree_centrality  \\\n",
       "88081              0.860056       7.263401           0.016807   \n",
       "92442              0.686789       2.664024           0.016807   \n",
       "92443              0.586629       2.932814           0.016807   \n",
       "92226              0.586629       2.932814           0.016807   \n",
       "88822              0.403294      10.189193           0.016807   \n",
       "92405              0.581977       2.309477           0.016807   \n",
       "87728              0.840557       7.242274           0.016807   \n",
       "91908              0.221328       2.322012           0.016807   \n",
       "92010              0.192011       2.345358           0.016807   \n",
       "99549              0.387172      15.983226           0.016807   \n",
       "89640              0.487578      10.275050           0.016807   \n",
       "90957              1.292540      10.763777           0.016807   \n",
       "92340              0.451387       2.128424           0.016807   \n",
       "89771              0.379721      10.167310           0.016807   \n",
       "89364              0.438307      10.224172           0.016807   \n",
       "87642              0.840557       7.242274           0.016807   \n",
       "96163              0.534168       9.332305           0.016807   \n",
       "98242              1.296299      10.947164           0.016807   \n",
       "88571              0.438307      10.224172           0.016807   \n",
       "90038              0.487578      10.275050           0.016807   \n",
       "87979              0.860056       7.263401           0.016807   \n",
       "109220             0.291216      11.358756           0.016807   \n",
       "101312             0.323239       2.395704           0.016807   \n",
       "112128             0.370873      12.479752           0.033613   \n",
       "97745              1.273134      10.990103           0.016807   \n",
       "\n",
       "        eigenvector_centrality            flat_model_type  \\\n",
       "88081                 0.006243           5 ROOM, Improved   \n",
       "92442                 0.047782           5 ROOM, Improved   \n",
       "92443                 0.047782           5 ROOM, Improved   \n",
       "92226                 0.047782           5 ROOM, Improved   \n",
       "88822                 0.001156           5 ROOM, Improved   \n",
       "92405                 0.047782           3 ROOM, Standard   \n",
       "87728                 0.006243           5 ROOM, Improved   \n",
       "91908                 0.047782           5 ROOM, Improved   \n",
       "92010                 0.047782           5 ROOM, Improved   \n",
       "99549                 0.000034           5 ROOM, Improved   \n",
       "89640                 0.001156           5 ROOM, Improved   \n",
       "90957                 0.000217       EXECUTIVE, Apartment   \n",
       "92340                 0.047782           5 ROOM, Improved   \n",
       "89771                 0.001156           5 ROOM, Improved   \n",
       "89364                 0.001156           5 ROOM, Improved   \n",
       "87642                 0.006243           5 ROOM, Improved   \n",
       "96163                 0.001179           5 ROOM, Improved   \n",
       "98242                 0.000594  5 ROOM, Premium Apartment   \n",
       "88571                 0.001156           5 ROOM, Improved   \n",
       "90038                 0.001156           5 ROOM, Improved   \n",
       "87979                 0.006243           5 ROOM, Improved   \n",
       "109220                0.000233  5 ROOM, Premium Apartment   \n",
       "101312                0.004414            4 ROOM, Model A   \n",
       "112128                0.000229      EXECUTIVE, Maisonette   \n",
       "97745                 0.000594  5 ROOM, Premium Apartment   \n",
       "\n",
       "        remaining_lease_years  floor_area_sqm storey_range  resale_price  \\\n",
       "88081               90.166667           121.0     28 TO 30     1100000.0   \n",
       "92442               90.333333           113.0     16 TO 18     1165000.0   \n",
       "92443               96.583333           113.0     40 TO 42     1256000.0   \n",
       "92226               96.750000           113.0     28 TO 30     1220000.0   \n",
       "88822               88.166667           112.0     01 TO 03      862000.0   \n",
       "92405               50.166667            88.0     01 TO 03      780000.0   \n",
       "87728               90.416667           119.0     07 TO 09      950000.0   \n",
       "91908               93.666667           112.0     22 TO 24     1205500.0   \n",
       "92010               93.500000           112.0     25 TO 27     1200000.0   \n",
       "99549               95.500000           113.0     10 TO 12      798000.0   \n",
       "89640               87.666667           112.0     01 TO 03      838000.0   \n",
       "90957               75.583333           144.0     10 TO 12      968000.0   \n",
       "92340               90.750000           114.0     34 TO 36     1245000.0   \n",
       "89771               87.666667           115.0     10 TO 12      908888.0   \n",
       "89364               87.916667           112.0     04 TO 06      853000.0   \n",
       "87642               90.500000           119.0     04 TO 06      908000.0   \n",
       "96163               94.750000           113.0     01 TO 03      942000.0   \n",
       "98242               93.416667           115.0     07 TO 09      798000.0   \n",
       "88571               88.416667           112.0     04 TO 06      838000.0   \n",
       "90038               87.500000           112.0     13 TO 15      900000.0   \n",
       "87979               90.166667           121.0     25 TO 27      990000.0   \n",
       "109220              94.583333           112.0     13 TO 15      820000.0   \n",
       "101312              95.083333            93.0     07 TO 09      840000.0   \n",
       "112128              61.750000           148.0     01 TO 03      998000.0   \n",
       "97745               93.750000           115.0     13 TO 15      800000.0   \n",
       "\n",
       "               error  \n",
       "88081   398580.25000  \n",
       "92442   396505.06250  \n",
       "92443   392089.43750  \n",
       "92226   387354.18750  \n",
       "88822   387018.59375  \n",
       "92405   385981.93750  \n",
       "87728   370618.68750  \n",
       "91908   366470.81250  \n",
       "92010   364515.75000  \n",
       "99549   363321.50000  \n",
       "89640   362070.25000  \n",
       "90957   356371.12500  \n",
       "92340   350600.25000  \n",
       "89771   348289.81250  \n",
       "89364   347398.06250  \n",
       "87642   345092.43750  \n",
       "96163   337933.68750  \n",
       "98242   334937.34375  \n",
       "88571   333318.53125  \n",
       "90038   326107.87500  \n",
       "87979   321754.56250  \n",
       "109220  316804.31250  \n",
       "101312  316428.96875  \n",
       "112128  315023.31250  \n",
       "97745   314628.09375  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Enter your code here\n",
    "\n",
    "df['error'] = abs(y_true - y_pred)\n",
    "\n",
    "sorted_df = df.sort_values(by='error', ascending=False)\n",
    "\n",
    "top_25_errors = sorted_df.head(25)\n",
    "\n",
    "print('Top 25 Test Sampels with the Largest Errors:')\n",
    "top_25_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B, Q2 (10 marks)\n",
    "---\n",
    "In Question B1, we used the Category Embedding model. This creates a feedforward neural network in which the categorical features get learnable embeddings. In this question, we will make use of a library called Pytorch-WideDeep. This library makes it easy to work with multimodal deep-learning problems combining images, text, and tables. We will just be utilizing the deeptabular component of this library through the TabMlp network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-widedeep in /opt/anaconda3/lib/python3.12/site-packages (1.6.5)\n",
      "Requirement already satisfied: pandas>=1.3.5 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch-widedeep) (2.2.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.21.6 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch-widedeep) (1.26.4)\n",
      "Requirement already satisfied: scipy<=1.12.0,>=1.7.3 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch-widedeep) (1.12.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch-widedeep) (1.5.1)\n",
      "Requirement already satisfied: gensim in /opt/anaconda3/lib/python3.12/site-packages (from pytorch-widedeep) (4.3.3)\n",
      "Requirement already satisfied: spacy in /opt/anaconda3/lib/python3.12/site-packages (from pytorch-widedeep) (3.8.4)\n",
      "Requirement already satisfied: opencv-contrib-python>=4.9.0.80 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch-widedeep) (4.11.0.86)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from pytorch-widedeep) (4.66.5)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch-widedeep) (2.7.0.dev20250115)\n",
      "Requirement already satisfied: torchvision>=0.15.0 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch-widedeep) (0.22.0.dev20250115)\n",
      "Requirement already satisfied: einops in /opt/anaconda3/lib/python3.12/site-packages (from pytorch-widedeep) (0.7.0)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/lib/python3.12/site-packages (from pytorch-widedeep) (1.14.1)\n",
      "Requirement already satisfied: torchmetrics>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch-widedeep) (1.5.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch-widedeep) (16.1.0)\n",
      "Requirement already satisfied: fastparquet>=2024.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch-widedeep) (2024.11.0)\n",
      "Requirement already satisfied: transformers>=4.37.0 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch-widedeep) (4.49.0)\n",
      "Requirement already satisfied: sentence-transformers>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch-widedeep) (3.4.1)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from pytorch-widedeep) (0.2.0)\n",
      "Requirement already satisfied: cramjam>=2.3 in /opt/anaconda3/lib/python3.12/site-packages (from fastparquet>=2024.2.0->pytorch-widedeep) (2.9.1)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from fastparquet>=2024.2.0->pytorch-widedeep) (2024.10.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from fastparquet>=2024.2.0->pytorch-widedeep) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.3.5->pytorch-widedeep) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.3.5->pytorch-widedeep) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.3.5->pytorch-widedeep) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn>=1.0.2->pytorch-widedeep) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn>=1.0.2->pytorch-widedeep) (3.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers>=2.3.0->pytorch-widedeep) (0.29.2)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers>=2.3.0->pytorch-widedeep) (10.4.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->pytorch-widedeep) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->pytorch-widedeep) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->pytorch-widedeep) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->pytorch-widedeep) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->pytorch-widedeep) (70.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->pytorch-widedeep) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0.0->pytorch-widedeep) (1.3.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchmetrics>=1.3.1->pytorch-widedeep) (0.14.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers>=4.37.0->pytorch-widedeep) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers>=4.37.0->pytorch-widedeep) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers>=4.37.0->pytorch-widedeep) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers>=4.37.0->pytorch-widedeep) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers>=4.37.0->pytorch-widedeep) (0.5.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/anaconda3/lib/python3.12/site-packages (from gensim->pytorch-widedeep) (5.2.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/anaconda3/lib/python3.12/site-packages (from spacy->pytorch-widedeep) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy->pytorch-widedeep) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy->pytorch-widedeep) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from spacy->pytorch-widedeep) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from spacy->pytorch-widedeep) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /opt/anaconda3/lib/python3.12/site-packages (from spacy->pytorch-widedeep) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/anaconda3/lib/python3.12/site-packages (from spacy->pytorch-widedeep) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from spacy->pytorch-widedeep) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/lib/python3.12/site-packages (from spacy->pytorch-widedeep) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy->pytorch-widedeep) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy->pytorch-widedeep) (0.9.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from spacy->pytorch-widedeep) (2.8.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy->pytorch-widedeep) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/anaconda3/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy->pytorch-widedeep) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->pytorch-widedeep) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->pytorch-widedeep) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->pytorch-widedeep) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers>=4.37.0->pytorch-widedeep) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers>=4.37.0->pytorch-widedeep) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers>=4.37.0->pytorch-widedeep) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers>=4.37.0->pytorch-widedeep) (2024.12.14)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy->pytorch-widedeep) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy->pytorch-widedeep) (0.1.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy->pytorch-widedeep) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy->pytorch-widedeep) (0.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->pytorch-widedeep) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->pytorch-widedeep) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-widedeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_widedeep.preprocessing import TabPreprocessor\n",
    "from pytorch_widedeep.models import TabMlp, WideDeep\n",
    "from pytorch_widedeep import Trainer\n",
    "from pytorch_widedeep.metrics import R2Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Divide the dataset (‘hdb_price_prediction.csv’) into train and test sets by using entries from the year 2020 and before as training data, and entries from 2021 and after as the test data（validation set is not required here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 87370\n",
      "Test set size: 29057\n"
     ]
    }
   ],
   "source": [
    "# TODO: Enter your code here\n",
    "\n",
    "df = df[df['year'] <= 2021].copy()\n",
    "\n",
    "train_df = df[df['year'] <= 2020].copy()\n",
    "test_df = df[df['year'] == 2021].copy()\n",
    "\n",
    "train_df.drop(columns=['year','full_address','nearest_stn'], inplace=True)\n",
    "test_df.drop(columns=['year','full_address','nearest_stn'], inplace=True)\n",
    "\n",
    "print('Train set size:', len(train_df))\n",
    "print('Test set size:', len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Refer to the documentation of Pytorch-WideDeep and perform the following tasks:\n",
    "https://pytorch-widedeep.readthedocs.io/en/latest/index.html\n",
    "* Use [**TabPreprocessor**](https://pytorch-widedeep.readthedocs.io/en/latest/examples/01_preprocessors_and_utils.html#2-tabpreprocessor) to create the deeptabular component using the continuous\n",
    "features and the categorical features. Use this component to transform the training dataset.\n",
    "* Create the [**TabMlp**](https://pytorch-widedeep.readthedocs.io/en/latest/pytorch-widedeep/model_components.html#pytorch_widedeep.models.tabular.mlp.tab_mlp.TabMlp) model with 2 hidden layers in the MLP, with 200 and 100 neurons respectively.\n",
    "* Create a [**Trainer**](https://pytorch-widedeep.readthedocs.io/en/latest/pytorch-widedeep/trainer.html#pytorch_widedeep.training.Trainer) for the training of the created TabMlp model with the root mean squared error (RMSE) cost function. Train the model for 60 epochs using this trainer, keeping a batch size of 64. (Note: set the *num_workers* parameter to 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/pytorch_widedeep/preprocessing/tab_preprocessor.py:364: UserWarning: Continuous columns will not be normalised\n",
      "  warnings.warn(\"Continuous columns will not be normalised\")\n",
      "epoch 1: 100%|█| 1366/1366 [00:15<00:00, 89.40it/s, loss=5.32e+10, metrics={'r2'\n",
      "epoch 2:  74%|▋| 1012/1366 [00:11<00:03, 90.22it/s, loss=1.17e+10, metrics={'r2'\n",
      "/opt/anaconda3/lib/python3.12/site-packages/executing/executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "/opt/anaconda3/lib/python3.12/ast.py:587: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return Constant(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 42\u001b[0m\n\u001b[1;32m     33\u001b[0m wide_deep \u001b[38;5;241m=\u001b[39m WideDeep(deeptabular \u001b[38;5;241m=\u001b[39m tab_mlp)\n\u001b[1;32m     35\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     36\u001b[0m     model\u001b[38;5;241m=\u001b[39mwide_deep,\n\u001b[1;32m     37\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     38\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[R2Score],\n\u001b[1;32m     39\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     40\u001b[0m )\n\u001b[0;32m---> 42\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     43\u001b[0m     X_tab\u001b[38;5;241m=\u001b[39mX_tab_train,\n\u001b[1;32m     44\u001b[0m     target\u001b[38;5;241m=\u001b[39mtrain_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresale_price\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     45\u001b[0m     n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m,\n\u001b[1;32m     46\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m\n\u001b[1;32m     47\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytorch_widedeep/utils/general_utils.py:62\u001b[0m, in \u001b[0;36malias.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m         kwargs[original_name] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(alt_name)\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytorch_widedeep/utils/general_utils.py:62\u001b[0m, in \u001b[0;36malias.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m         kwargs[original_name] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(alt_name)\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytorch_widedeep/utils/general_utils.py:62\u001b[0m, in \u001b[0;36malias.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m         kwargs[original_name] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(alt_name)\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytorch_widedeep/training/trainer.py:470\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, X_wide, X_tab, X_text, X_img, X_train, X_val, val_split, target, n_epochs, validation_freq, batch_size, train_dataloader, eval_dataloader, feature_importance_sample_size, finetune, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_container\u001b[38;5;241m.\u001b[39mon_train_begin(\n\u001b[1;32m    463\u001b[0m     {\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    467\u001b[0m     }\n\u001b[1;32m    468\u001b[0m )\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m--> 470\u001b[0m     epoch_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_epoch(train_loader, epoch)\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m validation_freq \u001b[38;5;241m==\u001b[39m (\n\u001b[1;32m    472\u001b[0m         validation_freq \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    473\u001b[0m     ):\n\u001b[1;32m    474\u001b[0m         epoch_logs, on_epoch_end_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch(\n\u001b[1;32m    475\u001b[0m             eval_loader, epoch_logs\n\u001b[1;32m    476\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytorch_widedeep/training/trainer.py:905\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[0;34m(self, train_loader, epoch)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, targett) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(t, train_loader):\n\u001b[1;32m    904\u001b[0m     t\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 905\u001b[0m     train_score, train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_step(data, targett, batch_idx)\n\u001b[1;32m    906\u001b[0m     print_loss_and_metric(t, train_loss, train_score)\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_container\u001b[38;5;241m.\u001b[39mon_batch_end(batch\u001b[38;5;241m=\u001b[39mbatch_idx)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytorch_widedeep/training/trainer.py:944\u001b[0m, in \u001b[0;36mTrainer._train_step\u001b[0;34m(self, data, target, batch_idx)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    943\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(y_pred, y)\n\u001b[0;32m--> 944\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_score(y_pred, y, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    946\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytorch_widedeep/training/trainer.py:1032\u001b[0m, in \u001b[0;36mTrainer._get_score\u001b[0;34m(self, y_pred, y, is_train)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1031\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1032\u001b[0m         score \u001b[38;5;241m=\u001b[39m metric(y_pred, y)\n\u001b[1;32m   1033\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1034\u001b[0m         score \u001b[38;5;241m=\u001b[39m metric(torch\u001b[38;5;241m.\u001b[39msigmoid(y_pred), y)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytorch_widedeep/metrics.py:39\u001b[0m, in \u001b[0;36mMultipleMetrics.__call__\u001b[0;34m(self, y_pred, y_true)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metrics:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(metric, Metric):\n\u001b[0;32m---> 39\u001b[0m         logs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix \u001b[38;5;241m+\u001b[39m metric\u001b[38;5;241m.\u001b[39m_name] \u001b[38;5;241m=\u001b[39m metric(y_pred, y_true)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(metric, TorchMetric):\n\u001b[1;32m     41\u001b[0m         metric\u001b[38;5;241m.\u001b[39mupdate(y_pred, y_true\u001b[38;5;241m.\u001b[39mint())  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytorch_widedeep/metrics.py:394\u001b[0m, in \u001b[0;36mR2Score.__call__\u001b[0;34m(self, y_pred, y_true)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumerator \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ((y_pred \u001b[38;5;241m-\u001b[39m y_true) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_examples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 394\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_true_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    395\u001b[0m y_true_avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_true_sum \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_examples\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdenominator \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ((y_true \u001b[38;5;241m-\u001b[39m y_true_avg) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO: Enter your code here\n",
    "continuous_cols = [\n",
    "    'dist_to_nearest_stn',\n",
    "    'dist_to_dhoby',\n",
    "    'degree_centrality',\n",
    "    'eigenvector_centrality',\n",
    "    'remaining_lease_years',\n",
    "    'floor_area_sqm'\n",
    "]\n",
    "\n",
    "cat_embed_cols = [\n",
    "    ('month', len(np.unique(df['month']))),\n",
    "    ('town', len(np.unique(df['town']))),\n",
    "    ('flat_model_type', len(np.unique(df['flat_model_type']))),\n",
    "    ('storey_range', len(np.unique(df['storey_range']))),\n",
    "]\n",
    "\n",
    "tab_preprocessor = TabPreprocessor(\n",
    "    continuous_cols=continuous_cols,\n",
    "    cat_embed_cols=cat_embed_cols\n",
    ")\n",
    "\n",
    "X_tab_train = tab_preprocessor.fit_transform(train_df)\n",
    "\n",
    "tab_mlp = TabMlp(\n",
    "    tab_preprocessor.column_idx,\n",
    "    cat_embed_input=tab_preprocessor.cat_embed_input,\n",
    "    cat_embed_dropout=0.1,\n",
    "    continuous_cols=continuous_cols,\n",
    "    mlp_hidden_dims=[200,100]\n",
    ")\n",
    "\n",
    "wide_deep = WideDeep(deeptabular = tab_mlp)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=wide_deep,\n",
    "    objective='regression',\n",
    "    metrics=[R2Score],\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    X_tab=X_tab_train,\n",
    "    target=train_df['resale_price'].values,\n",
    "    n_epochs=60,\n",
    "    batch_size=64\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Report the test RMSE and the test R2 value that you obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Trainer.predict() got an unexpected keyword argument 'X_tab_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: Enter your code here\u001b[39;00m\n\u001b[1;32m      3\u001b[0m X_test \u001b[38;5;241m=\u001b[39m tab_preprocessor\u001b[38;5;241m.\u001b[39mtransform(test_df)\n\u001b[0;32m----> 5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mpredict(X_tab_test \u001b[38;5;241m=\u001b[39m X_test)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# preds = trainer.predict(X_tab_test)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m y_true \u001b[38;5;241m=\u001b[39m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresale_price\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: Trainer.predict() got an unexpected keyword argument 'X_tab_test'"
     ]
    }
   ],
   "source": [
    "# TODO: Enter your code here\n",
    "\n",
    "X_test = tab_preprocessor.transform(test_df)\n",
    "\n",
    "y_pred = trainer.predict(X_tab_test = X_test)\n",
    "\n",
    "# preds = trainer.predict(X_tab_test)\n",
    "y_true = test_df['resale_price']\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f'Test RMSE: {rmse:.3f}')\n",
    "print(f'Test R2: {r2:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B, Q3 (10 marks)\n",
    "---\n",
    "Besides ensuring that your neural network performs well, it is important to be able to explain the model’s decision. **Captum** is a very handy library that helps you to do so for PyTorch models.\n",
    "\n",
    "Many model explainability algorithms for deep learning models are available in Captum. These algorithms are often used to generate an attribution score for each feature. Features with larger scores are more ‘important’ and some algorithms also provide information about directionality (i.e. a feature with very negative attribution scores means the larger the value of that feature, the lower the value of the output).\n",
    "\n",
    "In general, these algorithms can be grouped into two paradigms:\n",
    "- **perturbation based approaches** (e.g. Feature Ablation)\n",
    "- **gradient / backpropagation based approaches** (e.g. Saliency)\n",
    "\n",
    "The former adopts a brute-force approach of removing / permuting features one by one and does not scale up well. The latter depends on gradients and they can be computed relatively quickly. But unlike how backpropagation computes gradients with respect to weights, gradients here are computed **with respect to the input**. This gives us a sense of how much a change in the input affects the model’s outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/pty.py:95: DeprecationWarning: This process (pid=34546) is multi-threaded, use of forkpty() may lead to deadlocks in the child.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: captum in /opt/anaconda3/lib/python3.12/site-packages (0.7.0)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (from captum) (3.9.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from captum) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.6 in /opt/anaconda3/lib/python3.12/site-packages (from captum) (2.7.0.dev20250115)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from captum) (4.66.5)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.6->captum) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.6->captum) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.6->captum) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.6->captum) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.6->captum) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.6->captum) (70.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.6->captum) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.6->captum) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->captum) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->captum) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->captum) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->captum) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->captum) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->captum) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->captum) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->captum) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.6->captum) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import Saliency, InputXGradient, IntegratedGradients, GradientShap, FeatureAblation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> First, use the train set (year 2020 and before) and test set (year 2021) following the splits in Question B1 (validation set is not required here). To keep things simple, we will **limit our analysis to numeric / continuous features only**. Drop all categorical features from the dataframes. Standardise the features via **StandardScaler** (fit to training set, then transform all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 87370\n",
      "Test set size: 29057\n",
      "Standardized training features:\n",
      "   dist_to_nearest_stn  dist_to_dhoby  degree_centrality  \\\n",
      "0             0.417407      -1.010151          -0.136981   \n",
      "1             0.984169      -0.775978          -0.136981   \n",
      "2             0.551474      -0.510894          -0.136981   \n",
      "3             0.287854      -0.887089          -0.136981   \n",
      "4             0.600418      -0.501364          -0.136981   \n",
      "\n",
      "   eigenvector_centrality  remaining_lease_years  floor_area_sqm  \n",
      "0               -0.014527              -1.035566       -2.212177  \n",
      "1               -0.014527              -1.093501       -1.265110  \n",
      "2               -0.196828              -0.951882       -1.265110  \n",
      "3               -0.014527              -0.977631       -1.223934  \n",
      "4               -0.196828              -0.951882       -1.265110  \n",
      "Standardized test festures:\n",
      "       dist_to_nearest_stn  dist_to_dhoby  degree_centrality  \\\n",
      "87370             0.995728      -0.690689          -0.136981   \n",
      "87371             0.995728      -0.690689          -0.136981   \n",
      "87372             0.154775      -1.015974          -0.136981   \n",
      "87373            -0.290752      -0.692343          -0.136981   \n",
      "87374             0.234545      -0.769898          -0.136981   \n",
      "\n",
      "       eigenvector_centrality  remaining_lease_years  floor_area_sqm  \n",
      "87370               -0.196828              -0.823138       -2.171000  \n",
      "87371               -0.196828              -0.823138       -2.171000  \n",
      "87372               -0.014527              -1.215808       -1.223934  \n",
      "87373               -0.014527              -1.280180       -1.223934  \n",
      "87374               -0.014527              -1.286617       -1.223934  \n"
     ]
    }
   ],
   "source": [
    "# TODO: Enter your code here\n",
    "\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = df[df['year'] <= 2021].copy()\n",
    "\n",
    "train_df = df[df['year'] <= 2020].copy()\n",
    "test_df = df[df['year'] == 2021].copy()\n",
    "\n",
    "train_df.drop(columns=['year','full_address','nearest_stn'], inplace=True)\n",
    "test_df.drop(columns=['year','full_address','nearest_stn'], inplace=True)\n",
    "\n",
    "print('Train set size:', len(train_df))\n",
    "print('Test set size:', len(test_df))\n",
    "\n",
    "numeric_cols = [\n",
    "    'dist_to_nearest_stn',\n",
    "    'dist_to_dhoby',\n",
    "    'degree_centrality',\n",
    "    'eigenvector_centrality',\n",
    "    'remaining_lease_years',\n",
    "    'floor_area_sqm'\n",
    "]\n",
    "\n",
    "X_train = train_df[numeric_cols]\n",
    "y_train = train_df['resale_price']\n",
    "\n",
    "X_test = test_df[numeric_cols]\n",
    "y_test = test_df['resale_price']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=numeric_cols, index=X_train.index)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=numeric_cols, index=X_test.index)\n",
    "\n",
    "\n",
    "print('Standardized training features:')\n",
    "print(X_train_scaled_df.head())\n",
    "\n",
    "print('Standardized test festures:')\n",
    "print(X_test_scaled_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Follow this tutorial to generate the plot from various model explainability algorithms (https://captum.ai/tutorials/House_Prices_Regression_Interpret).\n",
    "Specifically, make the following changes:\n",
    "- Use a feedforward neural network with 3 hidden layers, each having 5 neurons. Train using Adam optimiser with learning rate of 0.001.\n",
    "- Use Input x Gradients, Integrated Gradients, DeepLift, GradientSHAP, Feature Ablation. To avoid long running time, you can limit the analysis to the first 1000 samples in test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreeLayer(\n",
       "  (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (lin2): Linear(in_features=5, out_features=5, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (lin3): Linear(in_features=5, out_features=5, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (lin4): Linear(in_features=5, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Enter your code here\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from captum.attr import DeepLift\n",
    "\n",
    "no_features = X_train.shape[1]\n",
    "no_hidden = 5\n",
    "no_labels = 1\n",
    "batch_size = 50\n",
    "num_epochs = 200\n",
    "lr = 0.001\n",
    "\n",
    "class ThreeLayer(nn.Module):\n",
    "    def __init__(self, no_features, no_hidden, no_labels):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(no_features, no_hidden)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.lin2 = nn.Linear(no_hidden, no_hidden)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.lin3 = nn.Linear(no_hidden, no_hidden)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.lin4 = nn.Linear(no_hidden, no_labels)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.lin4(self.relu3(self.lin3(self.relu2(self.lin2(self.relu1(self.lin1(input)))))))\n",
    "\n",
    "model = ThreeLayer(no_features, no_hidden, no_labels)\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1]/[200] running accumulative loss across all batches: 7774965539752960.000\n",
      "Epoch [21]/[200] running accumulative loss across all batches: 300713996028160.000\n",
      "Epoch [41]/[200] running accumulative loss across all batches: 294416219060992.000\n",
      "Epoch [61]/[200] running accumulative loss across all batches: 288993464245504.000\n",
      "Epoch [81]/[200] running accumulative loss across all batches: 286170761640576.000\n",
      "Epoch [101]/[200] running accumulative loss across all batches: 285116524858880.000\n",
      "Epoch [121]/[200] running accumulative loss across all batches: 284149964345984.000\n",
      "Epoch [141]/[200] running accumulative loss across all batches: 283902878851968.000\n",
      "Epoch [161]/[200] running accumulative loss across all batches: 282895485706240.000\n",
      "Epoch [181]/[200] running accumulative loss across all batches: 282621906126976.000\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = torch.tensor(X_train_scaled_df.values).float()\n",
    "y_train_tensor = torch.tensor(y_train.values).view(-1, 1).float()\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_scaled_df.values).float()\n",
    "y_test_tensor = torch.tensor(y_test.values).view(-1, 1).float()\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "def train(model, num_epochs=num_epochs, lr=lr):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss(reduction='sum')\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_iter:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            running_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        if epoch % 20 == 0:\n",
    "            print('Epoch [%d]/[%d] running accumulative loss across all batches: %.3f' % (epoch + 1, num_epochs, running_loss))\n",
    "        running_loss = 0.0\n",
    "\n",
    "train(model, num_epochs, lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 83257.24\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "outputs = model(X_test_tensor)\n",
    "err = np.sqrt(mean_squared_error(outputs.detach().numpy(), y_test_tensor.detach().numpy()))\n",
    "\n",
    "print(\"Mean Squared Error:\", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test = X_test_tensor[:1000]\n",
    "\n",
    "baseline = torch.zeros_like(X_test)\n",
    "\n",
    "ixg = InputXGradient(model)\n",
    "ig = IntegratedGradients(model)\n",
    "dl = DeepLift(model)\n",
    "gs = GradientShap(model)\n",
    "fa = FeatureAblation(model)\n",
    "\n",
    "ixg_attr_test = ixg.attribute(X_test)\n",
    "ig_attr_test = ig.attribute(X_test, baseline)\n",
    "dl_attr_test = dl.attribute(X_test, baseline)\n",
    "gs_attr_test = gs.attribute(X_test, baselines=baseline, n_samples=50, stdevs=0.09)\n",
    "fa_attr_test = fa.attribute(X_test)\n",
    "\n",
    "feature_names = X_test_scaled_df.columns.tolist()\n",
    "\n",
    "x_axis_data = np.arange(X_test.shape[1])\n",
    "x_axis_data_labels = list(map(lambda idx: feature_names[idx], x_axis_data))\n",
    "\n",
    "ixg_attr_test_sum = ixg_attr_test.detach().numpy().sum(0)\n",
    "ixg_attr_test_sum = -ixg_attr_test_sum\n",
    "ixg_attr_test_norm_sum = ixg_attr_test_sum / np.linalg.norm(ixg_attr_test_sum, ord=1)\n",
    "\n",
    "ig_attr_test_sum = ig_attr_test.detach().numpy().sum(0)\n",
    "ig_attr_test_sum = -ig_attr_test_sum\n",
    "ig_attr_test_norm_sum = ig_attr_test_sum / np.linalg.norm(ig_attr_test_sum, ord=1)\n",
    "\n",
    "dl_attr_test_sum = dl_attr_test.detach().numpy().sum(0)\n",
    "dl_attr_test_sum = -dl_attr_test_sum\n",
    "dl_attr_test_norm_sum = dl_attr_test_sum / np.linalg.norm(dl_attr_test_sum, ord=1)\n",
    "\n",
    "gs_attr_test_sum = gs_attr_test.detach().numpy().sum(0)\n",
    "gs_attr_test_sum = -gs_attr_test_sum\n",
    "gs_attr_test_norm_sum = gs_attr_test_sum / np.linalg.norm(gs_attr_test_sum,ord=1)\n",
    "\n",
    "fa_attr_test_sum = fa_attr_test.detach().numpy().sum(0)\n",
    "fa_attr_test_sum = -fa_attr_test_sum\n",
    "fa_attr_test_norm_sum = fa_attr_test_sum / np.linalg.norm(fa_attr_test_sum, ord=1)\n",
    "\n",
    "lin_weight = model.lin1.weight[0].detach().numpy()\n",
    "y_axis_lin_weight = lin_weight / np.linalg.norm(lin_weight, ord=1)\n",
    "\n",
    "width = 0.14\n",
    "legends = ['InputXGradient', 'IntegrateGradients', 'DeepLift', 'GradientShap', 'FeatureAblation']\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "ax = plt.subplot()\n",
    "ax.set_title('Comparing input feature importances across multiple algorithms and learned weights')\n",
    "ax.set_ylabel('Attributions')\n",
    "\n",
    "FONT_SIZE = 16\n",
    "plt.rc('font', size=FONT_SIZE) \n",
    "plt.rc('axes', titlesize=FONT_SIZE)\n",
    "plt.rc('axes', labelsize=FONT_SIZE)\n",
    "plt.rc('legend', fontsize=FONT_SIZE - 4)\n",
    "\n",
    "ax.bar(x_axis_data, ixg_attr_test_norm_sum, width, align='center', alpha=0.8, color='#eb5e7c')\n",
    "ax.bar(x_axis_data + width, ig_attr_test_norm_sum, width, align='center', alpha=0.7, color='#A90000')\n",
    "ax.bar(x_axis_data + 2 * width, dl_attr_test_norm_sum, width, align='center', alpha=0.6, color='#34b8e0')\n",
    "ax.bar(x_axis_data + 3 * width, gs_attr_test_norm_sum, width, align='center',  alpha=0.8, color='#4260f5')\n",
    "ax.bar(x_axis_data + 4 * width, fa_attr_test_norm_sum, width, align='center', alpha=1.0, color='#49ba81')\n",
    "ax.bar(x_axis_data + 5 * width, y_axis_lin_weight, width, align='center', alpha=1.0, color='grey')\n",
    "\n",
    "ax.autoscale_view()\n",
    "plt.tight_layout()\n",
    "\n",
    "ax.set_xticks(x_axis_data + 0.5)\n",
    "ax.set_xticklabels(x_axis_data_labels)\n",
    "\n",
    "plt.legend(legends, loc=3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Read the following [descriptions](https://captum.ai/docs/attribution_algorithms) and [comparisons](https://captum.ai/docs/algorithms_comparison_matrix) in Captum to build up your understanding of the difference of various explainability algorithms. Based on your plot, identify the three most important features for regression. Explain how each of these features influences the regression outcome.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# TODO: \\<Enter your answer here\\>\n",
    "Looking at the magnitude of the attributions across all methods, we can see that 'floor_area_sqm', 'dist_to_dhoby', and 'remaining_lease_years' stand out with large absolute attributions.\n",
    "\n",
    "'floor_area_sqm': larger floor area usually correlates with higher resale prices, since bigger flats are usually more expensive. A positive bar indicates that higher floor area leads to a higher predicted price.\n",
    "\n",
    "'dist_to_dhoby': the distance to dhoby can have a negative relationship with resale price, as the houses further away from a station are often less desirable. A negative bar for this feature suggests that as distance increases, predicted resale price decreases.\n",
    "\n",
    "'remaining_lease_years': houses with more remaining lease years usually fetch higher resale price, because buyers value the longer tenure. However, in this model, it is negative and it is less common for typical housing data. It might mean the model has learned an inverse relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B, Q4 (10 marks)\n",
    "---\n",
    "\n",
    "Model degradation is a common issue faced when deploying machine learning models (including neural networks) in the real world. New data points could exhibit a different pattern from older data points due to factors such as changes in government policy or market sentiments. For instance, housing prices in Singapore have been increasing and the Singapore government has introduced 3 rounds of cooling measures over the past years (16 December 2021, 30 September 2022, 27 April 2023).\n",
    "\n",
    "In such situations, the distribution of the new data points could differ from the original data distribution which the models were trained on. Recall that machine learning models often work with the assumption that the test distribution should be similar to train distribution. When this assumption is violated, model performance will be adversely impacted.  In the last part of this assignment, we will investigate to what extent model degradation has occurred.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/pty.py:95: DeprecationWarning: This process (pid=34546) is multi-threaded, use of forkpty() may lead to deadlocks in the child.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting alibi-detect\n",
      "  Downloading alibi_detect-0.12.0-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from alibi-detect) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.16.2 in /opt/anaconda3/lib/python3.12/site-packages (from alibi-detect) (1.26.4)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from alibi-detect) (2.2.2)\n",
      "Requirement already satisfied: Pillow<11.0.0,>=5.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from alibi-detect) (10.4.0)\n",
      "Collecting opencv-python<5.0.0,>=3.2.0 (from alibi-detect)\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from alibi-detect) (1.12.0)\n",
      "Collecting scikit-image<0.23,>=0.19 (from alibi-detect)\n",
      "  Downloading scikit_image-0.22.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=0.20.2 in /opt/anaconda3/lib/python3.12/site-packages (from alibi-detect) (1.5.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from alibi-detect) (4.49.0)\n",
      "Requirement already satisfied: dill<0.4.0,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from alibi-detect) (0.3.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.28.1 in /opt/anaconda3/lib/python3.12/site-packages (from alibi-detect) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from alibi-detect) (2.32.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=1.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from alibi-detect) (2.8.2)\n",
      "Requirement already satisfied: toml<1.0.0,>=0.10.1 in /opt/anaconda3/lib/python3.12/site-packages (from alibi-detect) (0.10.2)\n",
      "Requirement already satisfied: catalogue<3.0.0,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from alibi-detect) (2.0.10)\n",
      "Collecting numba!=0.54.0,<0.60.0,>=0.50.0 (from alibi-detect)\n",
      "  Downloading numba-0.59.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from alibi-detect) (4.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (2.9.0.post0)\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba!=0.54.0,<0.60.0,>=0.50.0->alibi-detect)\n",
      "  Downloading llvmlite-0.42.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas<3.0.0,>=1.0.0->alibi-detect) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas<3.0.0,>=1.0.0->alibi-detect) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=1.8.0->alibi-detect) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=1.8.0->alibi-detect) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (2024.12.14)\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-image<0.23,>=0.19->alibi-detect) (3.4.2)\n",
      "Requirement already satisfied: imageio>=2.27 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-image<0.23,>=0.19->alibi-detect) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-image<0.23,>=0.19->alibi-detect) (2023.4.12)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-image<0.23,>=0.19->alibi-detect) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn<2.0.0,>=0.20.2->alibi-detect) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn<2.0.0,>=0.20.2->alibi-detect) (3.5.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (0.29.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers<5.0.0,>=4.0.0->alibi-detect) (2024.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.0.0->alibi-detect) (1.16.0)\n",
      "Downloading alibi_detect-0.12.0-py3-none-any.whl (381 kB)\n",
      "Downloading numba-0.59.1-cp312-cp312-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_image-0.22.0-cp312-cp312-macosx_12_0_arm64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.42.0-cp312-cp312-macosx_11_0_arm64.whl (28.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python, llvmlite, scikit-image, numba, alibi-detect\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.43.0\n",
      "    Uninstalling llvmlite-0.43.0:\n",
      "      Successfully uninstalled llvmlite-0.43.0\n",
      "  Attempting uninstall: scikit-image\n",
      "    Found existing installation: scikit-image 0.24.0\n",
      "    Uninstalling scikit-image-0.24.0:\n",
      "      Successfully uninstalled scikit-image-0.24.0\n",
      "  Attempting uninstall: numba\n",
      "    Found existing installation: numba 0.60.0\n",
      "    Uninstalling numba-0.60.0:\n",
      "      Successfully uninstalled numba-0.60.0\n",
      "Successfully installed alibi-detect-0.12.0 llvmlite-0.42.0 numba-0.59.1 opencv-python-4.11.0.86 scikit-image-0.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install alibi-detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi_detect.cd import TabularDrift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Evaluate your model from B1 on data from year 2022 and report the test R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'hdb_price_prediction.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: Enter your code here\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhdb_price_prediction.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m train_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2020\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      7\u001b[0m test_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2021\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hdb_price_prediction.csv'"
     ]
    }
   ],
   "source": [
    "# TODO: Enter your code here\n",
    "\n",
    "df = pd.read_csv('hdb_price_prediction.csv')\n",
    "\n",
    "\n",
    "train_df = df[df['year'] <= 2020].copy()\n",
    "test_df = df[df['year'] == 2021].copy()\n",
    "\n",
    "train_df.drop(columns=['year','full_address','nearest_stn'], inplace=True)\n",
    "test_df.drop(columns=['year','full_address','nearest_stn'], inplace=True)\n",
    "\n",
    "print('Train set size:', len(train_df))\n",
    "print('Test set size:', len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m numeric_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdist_to_nearest_stn\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdist_to_dhoby\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdegree_centrality\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meigenvector_centrality\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      2\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mremaining_lease_years\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloor_area_sqm\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m categorical_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtown\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflat_model_type\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstorey_range\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m data_config \u001b[38;5;241m=\u001b[39m DataConfig(\n\u001b[1;32m      6\u001b[0m     target\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresale_price\u001b[39m\u001b[38;5;124m\"\u001b[39m],  \n\u001b[1;32m      7\u001b[0m     continuous_cols\u001b[38;5;241m=\u001b[39mnumeric_cols,\n\u001b[1;32m      8\u001b[0m     categorical_cols\u001b[38;5;241m=\u001b[39mcategorical_cols,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m trainer_config \u001b[38;5;241m=\u001b[39m TrainerConfig(\n\u001b[1;32m     11\u001b[0m     auto_lr_find\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,\n\u001b[1;32m     13\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m optimizer_config \u001b[38;5;241m=\u001b[39m OptimizerConfig()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataConfig' is not defined"
     ]
    }
   ],
   "source": [
    "numeric_cols = ['dist_to_nearest_stn','dist_to_dhoby','degree_centrality','eigenvector_centrality',\n",
    "                 'remaining_lease_years','floor_area_sqm']\n",
    "categorical_cols = ['month','town','flat_model_type','storey_range']\n",
    "\n",
    "data_config = DataConfig(\n",
    "    target=[\"resale_price\"],  \n",
    "    continuous_cols=numeric_cols,\n",
    "    categorical_cols=categorical_cols,\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True,\n",
    "    batch_size=1024,\n",
    "    max_epochs=50,\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"regression\",\n",
    "    layers=\"50\",  \n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "\n",
    "tabular_model.fit(train_df, \n",
    "                  optimizer=QHAdam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tabular_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m tabular_model\u001b[38;5;241m.\u001b[39mevaluate(test_df)\n\u001b[1;32m      2\u001b[0m predicted \u001b[38;5;241m=\u001b[39m tabular_model\u001b[38;5;241m.\u001b[39mpredict(test_df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tabular_model' is not defined"
     ]
    }
   ],
   "source": [
    "evaluation = tabular_model.evaluate(test_df)\n",
    "predicted = tabular_model.predict(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 70836.522\n",
      "Test R2: 0.810\n"
     ]
    }
   ],
   "source": [
    "y_true = test_df['resale_price']\n",
    "y_pred = predicted['resale_price_prediction']\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f'Test RMSE: {rmse:.3f}')\n",
    "print(f'Test R2: {r2:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Evaluate your model from B1 on data from year 2023 and report the test R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: Enter your code here\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m test_df_2 \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2023\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      5\u001b[0m test_df_2\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_address\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest_stn\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain set size (2020):\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(train_df))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: Enter your code here\n",
    "\n",
    "test_df_2 = df[df['year'] == 2023].copy()\n",
    "\n",
    "test_df_2.drop(columns=['year','full_address','nearest_stn'], inplace=True)\n",
    "\n",
    "print('Train set size (2020):', len(train_df))\n",
    "print('Test set size (2023):', len(test_df_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_2 = tabular_model.evaluate(df_test_2)\n",
    "predicted_2 = tabular_model.predict(df_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_2 = test_df['resale_price']\n",
    "y_pred_2 = predicted_2['resale_price_prediction']\n",
    "\n",
    "mse_2 = mean_squared_error(y_true_2, y_pred_2)\n",
    "rmse_2 = np.sqrt(mse_2)\n",
    "r2_2 = r2_score(y_true_2, y_pred_2)\n",
    "\n",
    "print(f'Test RMSE: {rmse_2:.3f}')\n",
    "print(f'Test R2: {r2_2:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Did model degradation occur for the deep learning model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# TODO: \\<Enter your answer here\\>\n",
    "Yes, model degradation occurred for the deep learning model, the R^2 value of the model in B1 (2021) is 0.801, but it dropped to ### for 2022 and ### for 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model degradation could be caused by [various data distribution shifts](https://huyenchip.com/2022/02/07/data-distribution-shifts-and-monitoring.html#data-shift-types): covariate shift (features), label shift and/or concept drift (altered relationship between features and labels).\n",
    "There are various conflicting terminologies in the [literature](https://www.sciencedirect.com/science/article/pii/S0950705122002854#tbl1). Let’s stick to this reference for this assignment.\n",
    "\n",
    "> Using the **Alibi Detect** library, apply the **TabularDrift** function with the training data (year 2020 and before) used as the reference and **detect which features have drifted** in the 2023 test dataset. Before running the statistical tests, ensure you **sample 1000 data points** each from the train and test data. Do not use the whole train/test data. (Hint: use this example as a guide https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_chi2ks_adult.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter your code here\n",
    "\n",
    "train_copy = df_train.copy()\n",
    "train_copy.drop(columns=['resale_price','month'],inplace=True)\n",
    "\n",
    "test_copy = df_test.copy()\n",
    "test_copy.drop(columns=['resale_price','month'],inplace=True)\n",
    "\n",
    "feature_names = train_copy.columns\n",
    "\n",
    "sample_train = train_copy.sample(1000, random_state = 42)\n",
    "sample_test = test_copy.sample(1000, random_state = 42)\n",
    "\n",
    "categories_per_feature = {f: None for f in range(sample_train.values.shape[1])}\n",
    "cd = TabularDrift(sample_train.values, \n",
    "                  p_val=.05, \n",
    "                  categories_per_feature=categories_per_feature)\n",
    "preds = cd.predict(sample_test.values)\n",
    "labels = ['No!', 'Yes!']\n",
    "print('Drift? {}'.format(labels[preds['data']['is_drift']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpreds = cd.predict(sample_test.values, drift_type='feature')\n",
    "for f in range(cd.n_features):\n",
    "    stat = 'Chi2' if f in list(categories_per_feature.keys()) else 'K-S'\n",
    "    fname = feature_names[f]\n",
    "    is_drift = fpreds['data']['is_drift'][f]\n",
    "    stat_val, p_val = fpreds['data']['distance'][f], fpreds['data']['p_val'][f]\n",
    "    print(f'{fname} -- Drift? {labels[is_drift]} -- {stat} {stat_val:.3f} -- p-value {p_val:.3f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Assuming that the flurry of housing measures have made an impact on the relationship between all the features and resale_price (i.e. P(Y|X) changes), which type of data distribution shift possibly led to model degradation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# TODO: \\<Enter your answer here\\>\n",
    "If the relationship between the features (X) and the target (Y) has changed, it would be a concept drift. This means that the way the features (like location, area, etc.) relate to the resale price has changed over time. Even if the input data looks similar, the rules or patterns that link these inputs to the price have shifted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> From your analysis via TabularDrift, which features contribute to this shift?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# TODO: \\<Enter your answer here\\>\n",
    "In the analysis, a p-value under 0.05 indicates that we can reject the null hypothesis - that there is no change in the feature's distribution. This means there is strong statistical evidence of drift in the feature. The features 'town', 'nearest_stn', 'eigenvector_centrality', 'flat_model_type', 'remaining_lease_years', and 'floor_area_sqm' have significantly shifted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Suggest 1 way to address model degradation and implement it, showing improved test R2 for year 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# TODO: \\<Enter your answer here\\>\n",
    "My suggestion is that we can retrain the model by adding 2023 data to the training set. This model updating allows the model to adapt to the new relationship between festures and resale_price, and we can evaluate the retrained model on 2023 data to see an improved R^2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter your code here\n",
    "\n",
    "train_df_old = df[df['year'] <= 2020].copy()\n",
    "new_df = df[df['year'] == 2023].copy\n",
    "\n",
    "cols_to_drop = ['year', 'full_address', 'nearest_stn']\n",
    "train_df_old.drop(columns=cols_to_drop, inplace=True)\n",
    "new_df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "retrain_df = pd.concat([train_df_old, new_df])\n",
    "print('Retraining set size:', len(retrain_df))\n",
    "\n",
    "test_2023_df = new_df.copy()\n",
    "\n",
    "numeric_cols = ['dist_to_neatest_stn',\n",
    "                'dis_to_dhoby',\n",
    "                'degree_centrality',\n",
    "                'eigenvector_centrality',\n",
    "                'remaining_lease_years',\n",
    "                'floor_area_sqm']\n",
    "categorical_cols = ['month', 'town', 'flat_model_type', 'storey_range']\n",
    "\n",
    "data_config = DataConfig(\n",
    "    target=[\"resale_price\"],\n",
    "    continuous_cols=numeric_cols,\n",
    "    categorical_cols=categorical_cols\n",
    ")\n",
    "\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True,\n",
    "    batch_size=1024,\n",
    "    max_epochs=50\n",
    ")\n",
    "\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"regression\",\n",
    "    layers=\"50\"\n",
    ")\n",
    "\n",
    "updated_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config\n",
    ")\n",
    "\n",
    "updated_model.fit(df_retrain)\n",
    "\n",
    "evaluation_updated = updated_model.evaluate(df_test_2023)\n",
    "predicted_updated = updated_model.predict(df_test_2023)\n",
    "\n",
    "y_true_updated = test_2023_df['resale_price'].values\n",
    "y_pred_updated = predicted_updated['resale_price_prediction'].values\n",
    "\n",
    "r2_updated = r2_score(y_true_updated, y_pred_updated)\n",
    "print(f\"Improved Test R2 on 2023 data: {r2_updated:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an improved R^2 scaore for 2023 showing an increase from ### to ### as we retrain the model by updating the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOG8ZhA98h3O6fnefkjOU9w",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
